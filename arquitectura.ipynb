{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquitectura del ``Autoencoder``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from keras import Sequential\n",
    "from keras import losses, metrics, optimizers\n",
    "from keras.applications import mobilenet\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, LeakyReLU, MaxPooling2D, Conv2DTranspose, GlobalAveragePooling2D, Reshape\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regla de la piramide geometrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regla de la piramide geometrica sirve para ayudar determinar el tamaño de las capas ocultas en base al tamaño de las capas de input y output y al numero de capas ocultas. \n",
    "\n",
    "Esta aproximacion esta propuesta por Masters(1993): \n",
    ">  \"For a three layer network with n input and m output neurons, the hidden layer would have sqrt(N * M) neurons.\"\n",
    ">\n",
    "> -- <cite> Masters, Timothy. Pratical neural network recipes in C++. Morgan Kaufmann, 1993.</cite>\n",
    "\n",
    "[Enlace al artículo](https://eulertech.wordpress.com/2018/01/02/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-network/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid_rule(h_layers, input_size, output_size):\n",
    "    layers = []\n",
    "    if h_layers < 1:\n",
    "        print(\"No layers\")\n",
    "        return []\n",
    "    print(\"Layers for input %d and output %d:\" % (input_size,  output_size))\n",
    "    rate = (input_size/output_size)**(1/(h_layers+1))\n",
    "    for l in range(h_layers):\n",
    "        layer_size = output_size*(rate**(h_layers-l))\n",
    "        layer_size = round(layer_size)\n",
    "        layers.append(layer_size)\n",
    "        print(\"Layer %d: %d neurons\" % (l+1, layer_size))\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMD(Earth Mover's Distance) ``WIP``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EMD es una medida de distancia entre distribuciones de probabilidad, que consiste en representar ambas distribuciones como montones de tierra, en los que la distancia se determina en cuanto es el trabajo minimo que llevaria transformar un monticulo en otro. Matematicamente a EMD se la conoce como la métrica de Wasserstein.\n",
    "\n",
    "$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(p_i-q_i)^2}$\n",
    "\n",
    "Siendo p y q la prediccion y el verdadero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMD_loss(y_true, y_pred):\n",
    "\tn = np.prod(y_true.shape)\n",
    "\tp = tf.math.subtract(y_true, y_pred)\n",
    "\tp = tf.math.square(p)\n",
    "\tp = tf.math.reduce_sum(p)\n",
    "\treturn tf.math.sqrt(tf.math.divide(p,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Éste ``encoder`` va a ser un modelo basado en ``transfer learning``, vamos a tomar la red de ``mobilenet``, entranada para imagenes de ``imagenet`` sin las capa de clasificacion final, con una entrada de tamaño _img\\_shape_ y en el output colocamos la 'representacion latente' una codificacion de la imagen que nos permitiría reconstruirla con un ``decoder``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet/preprocess_input\n",
    "# https://keras.io/guides/transfer_learning/\n",
    "def build_transf_encoder(dim_latente, img_shape, trainable=True):\n",
    "    inputs = Input(shape=img_shape)\n",
    "    x=tf.cast(inputs, tf.float32)\n",
    "    x=tf.keras.layers.Resizing(128,128)(x)\n",
    "    #x=keras.applications.mobilenet.preprocess_input(x)  #dataformat por defecto es chanel last\n",
    "    core = mobilenet.MobileNet(input_shape=((128,128,3)), weights=\"imagenet\", include_top=False)\n",
    "    core.trainable = trainable\n",
    "    model = core(x, training=trainable)\n",
    "    model = GlobalAveragePooling2D()(model)\n",
    "    repr_latente = Dense(dim_latente)(model)\n",
    "    return keras.Model(inputs, repr_latente)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " tf.cast (TFOpLambda)        (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      " resizing (Resizing)         (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " mobilenet_1.00_128 (Functio  (None, 4, 4, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                20500     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,249,364\n",
      "Trainable params: 3,227,476\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enc = build_transf_encoder(20, (32,32,3))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder denso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_encoder(dim_latente, img_shape, depth=2):\n",
    "    layer_sizes = pyramid_rule(depth, np.prod(img_shape), dim_latente)\n",
    "    model =  keras.Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    for ls in layer_sizes:\n",
    "        model.add(Dense(ls))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(dim_latente))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers for input 3072 and output 20:\n",
      "Layer 1: 574 neurons\n",
      "Layer 2: 107 neurons\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 574)               1763902   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 574)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 107)               61525     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 107)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                2160      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,827,587\n",
      "Trainable params: 1,827,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc = build_dense_encoder(20, (32,32,3))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_encoder2(dim_latente, img_shape, depth=2):\n",
    "    #layer_sizes = pyramid_rule(depth, np.prod(img_shape), dim_latente)\n",
    "    layer_sizes=list(1000 for _ in range(depth))\n",
    "    model =  keras.Sequential()\n",
    "    model.add(Flatten(input_shape=img_shape))\n",
    "    for ls in layer_sizes:\n",
    "        model.add(Dense(ls))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(dim_latente))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1000)              785000    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1000)              1001000   \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,788,002\n",
      "Trainable params: 1,788,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc = build_dense_encoder2(2, (28,28,1))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_encoder(dim_latente, img_shape, depth=2):\n",
    "    model =  keras.Sequential()\n",
    "    filter = 8\n",
    "    model.add(Conv2D(filter, (3,3), padding=\"same\", activation=\"relu\", input_shape=img_shape))\n",
    "    model.add(MaxPooling2D())\n",
    "    for _ in range(depth-1):\n",
    "        filter*=2\n",
    "        model.add(Conv2D(filter, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dim_latente))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_51 (Conv2D)          (None, 28, 28, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 16)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 20)                15700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,948\n",
      "Trainable params: 16,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc = build_conv_encoder(20, (28,28,1))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder denso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_decoder(dim_latente, img_shape, depth=2):\n",
    "    model = keras.Sequential()\n",
    "    layer_sizes = pyramid_rule(depth, dim_latente, np.prod(img_shape))\n",
    "    model.add(Dense(layer_sizes[0], input_dim=dim_latente))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    for i in range(1, depth):\n",
    "        model.add(Dense(layer_sizes[i], input_dim=dim_latente))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(np.prod(img_shape), activation=keras.activations.sigmoid))\n",
    "    model.add(Reshape(img_shape))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers for input 20 and output 3072:\n",
      "Layer 1: 107 neurons\n",
      "Layer 2: 574 neurons\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 107)               2247      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 107)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 574)               61992     \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 574)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3072)              1766400   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 32, 32, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,830,639\n",
      "Trainable params: 1,830,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc = build_dense_decoder(20, (32,32,3))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_decoder2(dim_latente, img_shape, depth=2):\n",
    "    model = keras.Sequential()\n",
    "    #layer_sizes = pyramid_rule(depth, dim_latente, np.prod(img_shape))\n",
    "    layer_sizes=list(1000 for _ in range(depth))\n",
    "    model.add(Dense(layer_sizes[0], input_dim=dim_latente))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    for i in range(1, depth):\n",
    "        model.add(Dense(layer_sizes[i], input_dim=dim_latente))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(np.prod(img_shape), activation=keras.activations.sigmoid))\n",
    "    model.add(Reshape(img_shape))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 1000)              3000      \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 784)               784784    \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,788,784\n",
      "Trainable params: 1,788,784\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "enc = build_dense_decoder2(2, (28,28,1))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_decoder(dim_latente, img_shape, depth=2):\n",
    "    startLayer = list(int(np.floor(d/(2**depth))) for d in img_shape)\n",
    "    filter = 8 * (2 ** (depth-1))\n",
    "    startLayer[-1] = filter\n",
    "    startLayer = tuple(startLayer) \n",
    "\n",
    "    model=keras.Sequential()\n",
    "    model.add(Dense(dim_latente, input_dim=(dim_latente)))\n",
    "    model.add(Dense(np.prod(startLayer)))              \n",
    "    model.add(Reshape(startLayer))      \n",
    "    for _ in range(depth):\n",
    "        model.add(Conv2DTranspose(filter, kernel_size=(3,3), strides=2, padding=\"same\", activation=\"relu\"))\n",
    "        filter/=2\n",
    "    model.add(Conv2D(img_shape[-1], (3, 3), padding=\"same\", activation=keras.activations.sigmoid))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_50 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 784)               16464     \n",
      "                                                                 \n",
      " reshape_18 (Reshape)        (None, 7, 7, 16)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_23 (Conv2D  (None, 14, 14, 16)       2320      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_24 (Conv2D  (None, 28, 28, 8)        1160      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 28, 28, 1)         73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,437\n",
      "Trainable params: 20,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dec = build_conv_decoder(20, (28,28,1))\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.Adam(0.0002, 0.5)\n",
    "#dim_latente=64\n",
    "#img_shape=X_train[0].shape\n",
    "\n",
    "#encoder = build_conv_encoder(dim_latente, img_shape)\n",
    "#decoder = build_conv_decoder(dim_latente, img_shape)\n",
    "#img = keras.layers.Input(img_shape)\n",
    "\n",
    "#encoder_rep = encoder(img)\n",
    "#autoencoder_out = decoder(encoder_rep)\n",
    "\n",
    "#autoencoder = keras.Model(img, autoencoder_out)\n",
    "#autoencoder.compile(loss='mse', optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "#out = autoencoder.predict(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El discriminador va a tener como entrada la codificacion latente de las imagenes y como salida una neurona que discrimina entre imagenes \"reales\" y \"falsas\". De esta forma entrenamos al encoder para que codifique con la distribucion que usemos para generar las \"imagenes reales\", en este caso, una distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(dim_latente, depth = 2):\n",
    "    #layer_sizes = pyramid_rule(depth, dim_latente, 1)\n",
    "    layer_sizes=list(1000 for _ in range(depth))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], input_dim=dim_latente))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    for i in range(1, depth):\n",
    "        model.add(Dense(layer_sizes[i]))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation=keras.activations.sigmoid))\n",
    "    encoded = Input(shape=dim_latente)\n",
    "    valid = model(encoded)\n",
    "    return keras.Model(encoded, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminador sensible a etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "def build_class_discriminator(dim_latente, clases, depth = 2):\n",
    "    # Rama latente\n",
    "    #latent_layer_sizes = pyramid_rule(depth, dim_latente, 1)\n",
    "    latent_layer_sizes=list(1000 for _ in range(depth))\n",
    "    latent_input = Input(shape=dim_latente)\n",
    "    currentLayer = latent_input\n",
    "    for i in range(0, depth):\n",
    "        currentLayer = Dense(latent_layer_sizes[i])(currentLayer)\n",
    "        currentLayer = LeakyReLU(alpha=0.2)(currentLayer)\n",
    "    x = keras.Model(inputs=latent_input, outputs=currentLayer)\n",
    "\n",
    "    # Rama de clases\n",
    "    #class_layer_sizes = pyramid_rule(depth, clases, 1)\n",
    "    class_layer_sizes=list(1000 for _ in range(depth))\n",
    "    class_input = Input(shape=clases)\n",
    "    currentLayer = class_input\n",
    "    for i in range(0, depth):\n",
    "        currentLayer = Dense(class_layer_sizes[i])(currentLayer)\n",
    "        currentLayer = LeakyReLU(alpha=0.2)(currentLayer)\n",
    "    y = keras.Model(inputs=class_input, outputs=currentLayer)\n",
    "\n",
    "    combined = tf.keras.layers.concatenate([x.output, y.output])\n",
    "    output = Dense(2)(combined)\n",
    "    output = Dense(1)(output)\n",
    "    return keras.Model(inputs = [x.input, y.input], outputs=output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1000)         21000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1000)         11000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 1000)         0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 1000)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1000)         1001000     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1000)         1001000     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 1000)         0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 1000)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2000)         0           ['leaky_re_lu_9[0][0]',          \n",
      "                                                                  'leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 2)            4002        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            3           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,038,005\n",
      "Trainable params: 2,038,005\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = build_class_discriminator(20, 10)\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
    "def build_class_discriminator2(dim_latente, clases, depth = 2):\n",
    "    layer_sizes=list(1000 for _ in range(depth))\n",
    "    latent_input = Input(shape=dim_latente)\n",
    "    class_input = Input(shape=clases)\n",
    "    concated_input = tf.keras.layers.concatenate([latent_input, class_input])\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], input_dim=dim_latente+clases))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    for i in range(1, depth):\n",
    "        model.add(Dense(layer_sizes[i]))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1, activation=keras.activations.sigmoid))\n",
    "    output = model(concated_input)\n",
    "    return keras.Model([latent_input, class_input], output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 20)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 1000)         21000       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1000)         11000       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 1000)         0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 1000)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 1000)         1001000     ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 1000)         1001000     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 1000)         0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 1000)         0           ['dense_19[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2000)         0           ['leaky_re_lu_9[0][0]',          \n",
      "                                                                  'leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 2)            4002        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 1)            3           ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,038,005\n",
      "Trainable params: 2,038,005\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "disc = build_class_discriminator2(20, 10)\n",
    "disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo para la construccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_AAE(dim_latente, img_shape, enc_model=build_dense_encoder, dec_model=build_dense_decoder, disc_model = build_discriminator, \n",
    "                compilation_kwargs={}, enc_kwargs={}, dec_kwargs={}, disc_kwargs={}):\n",
    "    #Parameters\n",
    "    disc_params = {\"dim_latente\":dim_latente}\n",
    "    disc_params.update(disc_kwargs)\n",
    "    enc_params = {\"dim_latente\":dim_latente, \"img_shape\":img_shape}\n",
    "    enc_params.update(enc_kwargs)\n",
    "    dec_params = {\"dim_latente\":dim_latente, \"img_shape\":img_shape}\n",
    "    dec_params.update(dec_kwargs)\n",
    "\n",
    "    cp = {\"ae_loss\":losses.mean_squared_error, \n",
    "          \"disc_loss\": losses.binary_crossentropy, \n",
    "          \"optimizer\" : keras.optimizers.Adam(0.0002, 0.5)\n",
    "         } #cp = compilation params\n",
    "    cp.update(compilation_kwargs)\n",
    "    # Discriminador\n",
    "    discriminator = disc_model(**disc_params)\n",
    "    discriminator.compile(loss=cp[\"disc_loss\"], metrics=\"accuracy\")\n",
    "\n",
    "    # Encoder y decoder\n",
    "    encoder = enc_model(**enc_params)\n",
    "    decoder = dec_model(**dec_params)\n",
    "\n",
    "    # Autoencoder\n",
    "    # el encoder toma un imagen y la codifica y el decoder toma la codificacion e intenta regenerar la imagen\n",
    "    img = Input(shape=img_shape, name=\"data\")\n",
    "    encoded = encoder(img)\n",
    "    reconstructed = decoder(encoded)\n",
    "    \n",
    "    if \"clases\" in disc_params.keys():\n",
    "        clase = Input(shape=disc_params[\"clases\"], name = \"labels\")\n",
    "        disc_input = [encoded, clase]\n",
    "        aae_input = [img, clase]\n",
    "    else:\n",
    "        disc_input = encoded\n",
    "        aae_input = img\n",
    "\n",
    "    # para el autoencoder adversario solo queremos entrenar el generador, no el discriminador\n",
    "    discriminator.trainable=False\n",
    "\n",
    "    # El discriminador evalua la validez de la codificacion\n",
    "    validez = discriminator(disc_input)\n",
    "\n",
    "    # Autoencoder adversario \n",
    "    a_autoencoder = keras.Model(aae_input, [reconstructed, validez])\n",
    "    a_autoencoder.compile(loss=[cp[\"ae_loss\"], cp[\"disc_loss\"]], optimizer=cp[\"optimizer\"])#, loss_weights=[0.999, 0.001])\n",
    "    return (encoder, decoder, discriminator, a_autoencoder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "20fa4f0f3884cdb253ada201871cf8c3f8a990e4bbc1c7fce1b9b4c9c33df28e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
